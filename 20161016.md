```
00:0C:29:94:B6:DE 192.168.56.101 dev001
00:0C:29:94:B6:D4  nat  dev001  可上外网

00:0C:29:76:C4:EC  192.168.56.103 serv003
00:0C:29:85:FB:C4  192.168.56.102 serv002
00:50:56:2F:38:58  192.168.56.101 serv001
00:0C:29:DB:E2:61  nat serv001 可上外网
```

# hosts

# ssh 
## authorized_keys
## know_hosts
```
trictHostKeyChecking no
UserKnownHostsFile /dev/null
```
# jdk1.8.0_77
```
me@corlin.cn
Cylgame1934bj
```
# hadoop
scp -r hadoop-2.6.3 root@serv001:/opt/cdp/


# etc/profile
```
HADOOP_HOME=/opt/cdp/hadoop-2.6.3
export HADOOP_HOME


JAVA_HOME=/usr/java/jdk1.8.0_77
PATH=$PATH:/usr/java/jdk1.8.0_77/bin:/opt/cdp/hadoop-2.6.3/bin

export JAVA_HOME
export PATH

HADOOP_CONF_DIR=/opt/cdp/hadoop-2.6.3/etc/hadoop
YARN_CONF_DIR=/opt/cdp/hadoop-2.6.3/etc/hadoop
export YARN_CONF_DIR
export HADOOP_CONF_DIR
export SPARK_HOME=/opt/cdp/spark-1.6.2-bin-hadoop2.6
```
# spark
slaves

# weburil
```
http://dev001:50070/dfshealth.html#tab-datanode
http://dev001:16030/rs-status
http://dev001:8088/cluster
http://dev001:8088/cluster/nodes
http://dev001:8088/proxy/application_1476613791517_0005/jobs/
```

# yarn
```
 <property>
    
<description>The hostname of the RM.</description>
    
<name>yarn.resourcemanager.hostname</name>
    
<value>dev001</value>
  
</property>    
```

# run spark job
